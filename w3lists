#!/usr/bin/env python
# Create thread trees by following in-reply-to links from lists.w3.org, such as
# http://lists.w3.org/Archives/Public/www-style/2014Apr/
# https://lists.w3.org/Archives/Public/${list}/mboxes/${year}-${month}.mbx
import argparse
import contextlib
import datetime
import email
import glob
import io
import json
import logging
import mailbox
from operator import attrgetter
import os
import re
import rfc822
import urllib2
import sys
#from xml.etree import ElementTree
from lxml import etree
logger = logging.getLogger('w3lists')
logging.basicConfig()

class w3lists(object):
	def __init__(self):
		self.message_by_id = {}
		self.normalized_url = {}

	def load_mbox(self, path, filter =None):
		path = os.path.expanduser(path)
		if os.path.isdir(path):
			for file in glob.glob(os.path.join(path, '*.mbx')):
				self.load_mbox(file, filter)
			return
		logger.info('Loading %s', path)
		mbox = mailbox.mbox(path)
		for mbmsg in mbox:
			m = w3lists.message(mbmsg)
			if filter and not filter(m):
				continue
			m.archived_at = self.normalize_url(m.archived_at)
			self.message_by_id[m.id] = m

	def normalize_url(self, url):
		normalized = self.normalized_url.get(url)
		if normalized:
			return normalized
		normalized = self._normalize_url(url)
		if not normalized:
			return url
		self.normalized_url[url] = normalized
		return normalized
	
	def _normalize_url(self, url):
		try:
			with contextlib.closing(urllib2.urlopen(url)) as response:
				redir = response.geturl()
			if redir != url:
				logger.debug('Normalized %s from %s', redir, url)
				return redir
			return None
		except urllib2.HTTPError as err:
			if err.code == 300:
				logger.debug('300 from %s', url)
				t = etree.parse(err)
				etree.tostring(t)
				hrefs = map(lambda a: a.attrib['href'], t.findall('.//li/a'))
				for href in hrefs:
					if 'www-style' in href:
						return href
				return hrefs[0]
			logging.error('HTTP %d for %s', err.code, url)
			return None
#		except:
#			err = sys.exc_info()[0]
#			logging.error('%s: %s', self.archived_at, err)

	def link_replies(self):
		logger.info("Linking replies...")
		for m in self.message_by_id.itervalues():
			m.link_in_reply_to(self.message_by_id)

	def dump_reply_tree(self, output):
		output.write('<!DOCTYPE html>\n'
			'<html>\n'
			'<head>\n'
			'<meta charset="utf-8">\n'
			'</head>\n'
			'<body>\n'
			'<ol>\n')
		for m in sorted(filter(lambda m: m.in_reply_to is None, self.message_by_id.itervalues()), key=attrgetter('date')):
			m.dump_reply_tree(output)
		output.write('</ol></body></html>\n')

	class message(object):
		def __init__(self, mbmsg):
			self.archived_at = self.strip_angle_brackets(mbmsg['archived-at'])
			self.date = datetime.datetime.fromtimestamp(rfc822.mktime_tz(rfc822.parsedate_tz(mbmsg['date'])))
			self.from_address = self.decode_header_to_unicode(mbmsg['from'])
			self.id = email.Utils.parseaddr(mbmsg['message-id'])[1]
			self.in_reply_to_id = mbmsg['in-reply-to']
			if self.in_reply_to_id:
				self.in_reply_to_id = email.Utils.parseaddr(self.in_reply_to_id)[1]
			self.subject = mbmsg['subject']
			self.in_reply_to = None
			self.replies = []

		@staticmethod
		def decode_header_to_unicode(text):
			decoded = email.header.decode_header(text)
			return u''.join([unicode(text, charset or 'ascii') for text, charset in decoded])

		re_angle_bracket = re.compile(r'<([^>]*)>')

		def strip_angle_brackets(self, text):
			match = self.re_angle_bracket.search(text)
			if match:
				return match.group(1)
			return text

		def link_in_reply_to(self, message_by_id):
			assert not self.in_reply_to
			in_reply_to_id = self.in_reply_to_id
			if not in_reply_to_id:
				return
			in_reply_to = message_by_id.get(in_reply_to_id)
			if not in_reply_to:
				logger.warn('Message id %s not loaded', in_reply_to_id)
				return
			self.in_reply_to = in_reply_to
			in_reply_to.replies.append(self)

		def dump_reply_tree(self, output):
			output.write('<li><a href="%s">%s</a> %s %s' % (self.archived_at, self.subject, self.from_address, self.date))
			if self.replies:
#				output.write(' %d replies' % len(self.replies))
				output.write('\n<ol>\n')
				for r in sorted(self.replies, key=attrgetter('date')):
					r.dump_reply_tree(output)
				output.write('</ol>\n')
			output.write('</li>\n')

def main():
	reload(sys).setdefaultencoding('utf-8')
	parser = argparse.ArgumentParser(description='lists.w3.org scraper')
	parser.add_argument('--filter', '-f')
	parser.add_argument('--mbox', '-m', default='~/Downloads')
	parser.add_argument('--redir', '-r', default='redir.json')
	parser.add_argument('--verbose', '-v', action='append_const', const=1)
#	parser.add_argument('url', nargs='*')
	args = parser.parse_args()
	if args.verbose:
		logging.basicConfig(level=logging.INFO if len(args.verbose) == 1 else logging.DEBUG)
	l = w3lists()
	if os.path.exists(args.redir):
		with open(args.redir, 'r') as f:
			l.normalized_url = json.load(f)
	l.load_mbox(args.mbox, (lambda m: re.search(args.filter, m.subject, re.I)) if args.filter else None)
	l.link_replies()
	with open(args.redir, 'w') as f:
		json.dump(l.normalized_url, f, indent=0)
	l.dump_reply_tree(sys.stdout)
	logger.info("Completed")

main()
