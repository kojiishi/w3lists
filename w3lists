#!/usr/bin/env python
# Create thread trees by following in-reply-to links from lists.w3.org, such as
# http://lists.w3.org/Archives/Public/www-style/2014Apr/
import argparse
import io
import logging
from operator import attrgetter
import re
import requests
import string
import traceback
from urlparse import urljoin
import sys
from xml.etree import ElementTree as ET

class w3lists(object):
	def __init__(self):
		self.messages = {}

	reListItem = re.compile(r'<li><a href="(?P<href>[^"]+)">(?P<subject>[^<]+)</a>')

	def load(self, url, filter =None):
		logging.info(url)
		r = requests.get(url)
		for m in w3lists.reListItem.finditer(r.text):
			if filter:
				subject = m.group('subject')
				if not re.search(filter, subject, re.I):
					continue
			href = m.group('href')
			self.addurl(urljoin(url, href), subject)

	def addurl(self, url, subject =None):
		m = self.messages.get(url)
		if m: return m
		m = w3lists.message(url, subject)
		try:
			m.load()
			if url != m.url:
				redirected = self.messages.get(m.url)
				if redirected: return redirected
		except Exception as err:
			logging.error("Failed to load the message: %s\n%s" % (url, traceback.format_exc()))
		self.messages[m.url] = m
		return m

	def linkreplies(self):
		logging.debug("Linking replies...")
		for m in self.messages.values():
			while True:
				parenturl = m.inreplytourl
				if not parenturl: break
				parent = self.addurl(parenturl)
				parent.addreply(m)
				m = parent

	def dump_reply_tree(self, output):
		for m in sorted(self.messages.values(), key=attrgetter('date')):
			if m.inreplyto:
				logging.debug("inreplyto %s\n\t%s\n\t%s %s %s\n" % (m.inreplyto.url, m.subject, m.date, m.url, m.author))
				continue
			m.dump_reply_tree(output)

	class message:
		def __init__(self, url, subject =None):
			self.url = url
			self.author = None
			self.date = None
			self.inreplyto = None
			self.inreplytohref = None
			self.replies = []
			self.subject = subject
			self.status_code = 0

		re_angle_bracket = re.compile(r'<([^>]*)>')

		def load(self):
			logging.info(self.url)
			# requests.get(url, streaming=true) and ET.parse(r.raw) will reslut r.status_code=0, so use BytesIO instead
			r = requests.get(self.url)
			self.status_code = r.status_code
			et = ET.parse(io.BytesIO(r.content))
			if self.status_code != 200:
				logging.error("HTTP Status %d: %s" % (self.status_code, self.url))
			elif len(r.history) > 0: # there were auto-redirects
				self.url = r.url
			e = et.find('.//{http://www.w3.org/1999/xhtml}span[@id="message-id"]')
			if e is not None:
				m = w3lists.message.re_angle_bracket.search(string.join(e.itertext()))
				if m:
					self.id = m.group(1)
			e = et.find('.//{http://www.w3.org/1999/xhtml}meta[@name="Author"]')
			if e is not None:
				self.author = e.get('content')
			e = et.find('.//{http://www.w3.org/1999/xhtml}meta[@name="Date"]')
			if e is not None:
				self.date = e.get('content')
			e = et.find('.//{http://www.w3.org/1999/xhtml}meta[@name="Subject"]')
			if e is not None:
				self.subject = e.get('content')
			for e in et.iter('{http://www.w3.org/1999/xhtml}a'):
				if e.text == 'In reply to':
					self.inreplytohref = e.get('href')
			logging.debug("%s %s %s %s" % (self.date, self.id, self.subject, self.inreplytohref))
			if not self.id:
				logging.error("Response not in expected format: " + self.url)
				logging.debug(html)
				return

		@property
		def inreplytourl(self):
			if self.inreplytohref:
				return urljoin(self.url, self.inreplytohref)
			return None

		def addreply(self, reply):
			if self == reply.inreplyto:
				return
			if reply.inreplyto:
				if self.url == reply.inreplyto.url:
					return
				assert False, "inreplyto already set to different object"
			for r in self.replies:
				if r.url == reply.url:
					logging.warning("different inreplyto but in replies")
					return
			self.replies.append(reply)
			reply.inreplyto = self
			if not self.subject: self.subject = reply.subject
			if not self.date: self.date = reply.date

		def dump_reply_tree(self, output):
			output.write("%s\n" % (self.subject))
			self.dump_oneline(output)
			self.dump_replies(output)

		def dump_oneline(self, output, indent = 1):
			output.write("\t" * indent)
			if self.status_code != 200: output.write("Status=%d " % self.status_code)
			output.write("%s %s %s\n" % (self.url, self.date, self.author))

		def dump_replies(self, output, indent =1):
			for r in self.replies:
				r.dump_oneline(output, indent)
				indent += 1
			for r in reversed(self.replies):
				indent -= 1
				r.dump_replies(output, indent)

def main():
	reload(sys).setdefaultencoding('utf-8')
	parser = argparse.ArgumentParser(description='lists.w3.org scraper')
	parser.add_argument('--filter', '-f')
	parser.add_argument('--debug', '-d', action='store_true')
	parser.add_argument('--verbose', '-v', action='store_true')
	parser.add_argument('url', nargs='+')
	args = parser.parse_args()
	if args.debug: logging.basicConfig(level=logging.DEBUG)
	elif args.verbose: logging.basicConfig(level=logging.INFO)
	l = w3lists()
	for url in args.url:
		l.load(url, args.filter)
	l.linkreplies()
	l.dump_reply_tree(sys.stdout)
	logging.info("Completed")

main()
