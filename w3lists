#!/usr/bin/env python
# Create thread trees by following in-reply-to links from lists.w3.org, such as
# http://lists.w3.org/Archives/Public/www-style/2014Apr/

import argparse
import HTMLParser
import logging
import re
import requests
from urlparse import urljoin
import sys

class w3lists(object):
	def __init__(self):
		self.messages = {}

	reListItem = re.compile(r'<li><a href="(?P<href>[^"]+)">(?P<subject>[^<]+)</a>')

	def load(self, url, filter =None):
		logging.info(url)
		r = requests.get(url)
		for m in w3lists.reListItem.finditer(r.text):
			if filter:
				subject = m.group('subject')
				if not re.search(filter, subject, re.I):
					continue
			href = m.group('href')
			self.addurl(urljoin(url, href))

	def addurl(self, url):
		m = self.messages.get(url)
		if m: return m
		m = w3lists.message(url)
		try:
			m.load()
		except Exception as err:
			logging.error("Failed to load the message: %s\n%s" % (url, err))
		self.messages[m.url] = m
		return m

	def linkreplies(self):
		logging.debug("Linking replies...")
		for m in self.messages.values():
			while True:
				parenturl = m.inreplytourl
				if not parenturl: break
				parent = self.addurl(parenturl)
				if not parent.subject: parent.subject = m.subject
				parent.addreply(m)
				m = parent

	def dumpreplies(self, output):
		for m in self.messages.values():
			if m.inreplyto:
				logging.debug("inreplyto %s\n\t%s\n\t%s %s %s\n" % (m.inreplyto.url, m.subject, m.date, m.url, m.author))
				continue
			output.write("%s\n" % (m.subject))
			m.dump_oneline(output, "\t")
			m.dumpreplies(output)

	class message:
		def __init__(self, url):
			self.author = None
			self.date = None
			self.inreplyto = None
			self.inreplytohref = None
			self.replies = []
			self.subject = None
			self.status_code = 0
			self.url = url

		reid = re.compile(r'<span id="message-id"><dfn>[^<]*</dfn>: &lt;(?P<id>.+)&gt;')
		refrom = re.compile(r'<meta name="Author" content="(?P<from>[^"]*)" />')
		redate = re.compile(r'<meta name="Date" content="(?P<date>[-0-9]+)" />')
		resubject = re.compile(r'<meta name="Subject" content="(?P<subject>[^"]*)" />')
		reinreplyto = re.compile(r'<a href="(?P<href>[^"]+)"\s+title="[^"]*">In reply to</a>')

		def load(self):
			logging.info(self.url)
			r = requests.get(self.url)
			self.status_code = r.status_code
			if self.status_code != 200:
				logging.error("HTTP Status %d: %s" % (self.status_code, self.url))
			elif len(r.history) > 0: # there were auto-redirects
				self.url = r.url
			html = r.text
			parser = HTMLParser.HTMLParser()
			m = w3lists.message.reid.search(html)
			self.id = parser.unescape(m.group('id')) if m else None
			m = w3lists.message.refrom.search(html)
			self.author = parser.unescape(m.group('from')) if m else None
			m = w3lists.message.redate.search(html)
			self.date = m.group('date') if m else None
			m = w3lists.message.resubject.search(html)
			self.subject = parser.unescape(m.group('subject')) if m else None
			m = w3lists.message.reinreplyto.search(html)
			self.inreplytohref = parser.unescape(m.group('href')) if m else None
			logging.debug("%s %s %s %s" % (self.date, self.id, self.subject, self.inreplytohref))
			if not self.id:
				logging.error("Response not in expected format: " + self.url)
				logging.debug(html)
				return

		@property
		def inreplytourl(self):
			if self.inreplytohref:
				return urljoin(self.url, self.inreplytohref)
			return None

		def addreply(self, reply):
			if reply.inreplyto:
				if self.url == reply.inreplyto.url:
					return
				raise Exception
			self.replies.append(reply)
			reply.inreplyto = self
		
		def dump_oneline(self, output, prefix =''):
			output.write("%s%s%s %s %s\n" % (prefix,
				"" if self.status_code == 200 else "Status=%d " % self.status_code,
				self.date, self.url, self.author))
	
		def dumpreplies(self, output, prefix =''):
			prefix = prefix + "\t"
			for r in self.replies:
				r.dump_oneline(output, prefix)
				if len(r.replies) > 0:
					r.dumpreplies(output, prefix)

def main():
	parser = argparse.ArgumentParser(description='lists.w3.org scraper')
	parser.add_argument('--filter', '-f')
	parser.add_argument('--debug', '-d', action='store_true')
	parser.add_argument('--verbose', '-v', action='store_true')
	parser.add_argument('url', nargs='+')
	args = parser.parse_args()
	if args.debug: logging.basicConfig(level=logging.DEBUG)
	elif args.verbose: logging.basicConfig(level=logging.INFO)
	l = w3lists()
	for url in args.url:
		l.load(url, args.filter)
	l.linkreplies()
	l.dumpreplies(sys.stdout)

main()
